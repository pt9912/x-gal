# v1.4.0 Implementation Plan

**Status:** üîÑ Concept
**Timeline:** Q3 2026 (Estimated)
**Focus:** Advanced Traffic Management & Multi-Cloud + gRPC Transformations

---

## Mission

**"Bring gRPC to GAL with seamless Protobuf transformations across all providers."**

Enable users to transform gRPC request/response messages using Protobuf descriptors, making gRPC services as easy to manage as REST APIs with GAL's provider-agnostic configuration.

---

## Feature Overview

| Feature | Status | Effort | Priority |
|---------|--------|--------|----------|
| **1. gRPC Transformations** | üîÑ Pending | 3-4 weeks | üî¥ High |
| **2. Cloud Provider Support (AWS)** | üîÑ Pending | 4 weeks | üü° Medium |
| **3. Cloud Provider Support (Azure)** | üîÑ Pending | 3 weeks | üü° Medium |
| **4. Cloud Provider Support (GCP)** | üîÑ Pending | 3 weeks | üü° Medium |
| **5. A/B Testing & Traffic Splitting** | üîÑ Pending | 2 weeks | üü° Medium |
| **6. Request Mirroring/Shadowing** | üîÑ Pending | 2 weeks | üü¢ Low |
| **7. Advanced Routing** | üîÑ Pending | 2 weeks | üü¢ Low |
| **8. GraphQL Support** | üîÑ Pending | 3 weeks | üü¢ Low |

**Total Effort:** ~22-24 weeks (5-6 months)
**Progress:** 0/8 Features (0%)

---

## Feature 1: gRPC Transformations (DETAILED)

**Status:** üîÑ Pending
**Priority:** üî¥ High
**Effort:** 3-4 weeks

### Motivation

- **Problem**: gRPC services need body transformations (add trace IDs, remove secrets, rename fields) just like REST APIs
- **Challenge**: Each provider has different mechanisms for Protobuf handling
- **Solution**: GAL provides unified config for gRPC transformations with proto descriptor management

### Configuration Model

```python
# gal/config.py

@dataclass
class ProtoDescriptor:
    """Protobuf descriptor configuration."""
    name: str                    # Descriptor name (e.g., "user_service")
    source: str                  # "file", "inline", "url"
    path: str = ""               # Path to .proto or .desc file
    content: str = ""            # Inline proto definition
    url: str = ""                # URL to download proto file

@dataclass
class GrpcTransformation:
    """gRPC transformation configuration."""
    enabled: bool = True
    proto_descriptor: str = ""   # Reference to ProtoDescriptor name
    package: str = ""            # Protobuf package (e.g., "user.v1")
    service: str = ""            # Service name (e.g., "UserService")
    request_type: str = ""       # Message type (e.g., "CreateUserRequest")
    response_type: str = ""      # Message type (e.g., "CreateUserResponse")

    # Transformation rules (reuse existing Body Transformation)
    request_transform: Optional[RequestBodyTransformation] = None
    response_transform: Optional[ResponseBodyTransformation] = None

@dataclass
class Route:
    # ... existing fields ...
    grpc_transformation: Optional[GrpcTransformation] = None

@dataclass
class Config:
    # ... existing fields ...
    proto_descriptors: List[ProtoDescriptor] = field(default_factory=list)
```

### YAML Configuration Example

```yaml
# Proto Descriptors (global)
proto_descriptors:
  - name: user_service_proto
    source: file
    path: /etc/gal/protos/user.desc

  - name: order_service_proto
    source: inline
    content: |
      syntax = "proto3";
      package order.v1;

      service OrderService {
        rpc CreateOrder(CreateOrderRequest) returns (CreateOrderResponse);
      }

      message CreateOrderRequest {
        string user_id = 1;
        repeated string product_ids = 2;
      }

# Services
services:
  - name: user_grpc_service
    protocol: grpc
    upstream:
      host: user-grpc-backend
      port: 50051

    routes:
      - path_prefix: /user.v1.UserService/CreateUser
        grpc_transformation:
          enabled: true
          proto_descriptor: user_service_proto
          package: user.v1
          service: UserService
          request_type: CreateUserRequest
          response_type: CreateUserResponse

          request_transform:
            add_fields:
              trace_id: "{{uuid}}"
              timestamp: "{{timestamp}}"
              gateway_version: "GAL-v1.4.0"
            remove_fields:
              - internal_secret
              - debug_info
            rename_fields:
              user_id: userId
              email_address: email

          response_transform:
            filter_fields:
              - password_hash
              - internal_id
            add_fields:
              server_time: "{{timestamp}}"
              server_id: "gateway-01"
```

### Provider Implementations

#### Envoy (Lua Filter)

**File:** `gal/providers/envoy.py`

```python
def _generate_grpc_transformation_envoy(self, route):
    """Generate Envoy Lua filter for gRPC transformation."""
    if not route.grpc_transformation or not route.grpc_transformation.enabled:
        return None

    grpc = route.grpc_transformation
    proto_desc = self._get_proto_descriptor(grpc.proto_descriptor)

    lua_code = f'''
function envoy_on_request(request_handle)
    local pb = require("pb")

    -- Load proto descriptor (once per worker)
    if not _proto_loaded then
        pb.loadfile("{proto_desc.path}")
        _proto_loaded = true
    end

    -- Get gRPC message body
    local body = request_handle:body()
    if not body then
        return
    end

    -- Decode Protobuf message
    local msg = pb.decode("{grpc.request_type}", body:getBytes(0, body:length()))

    -- Apply transformations
    {self._generate_grpc_request_transform_lua(grpc.request_transform)}

    -- Encode back to Protobuf
    local new_body = pb.encode("{grpc.request_type}", msg)
    body:setBytes(new_body)
end

function envoy_on_response(response_handle)
    local pb = require("pb")

    local body = response_handle:body()
    if not body then
        return
    end

    local msg = pb.decode("{grpc.response_type}", body:getBytes(0, body:length()))

    -- Apply response transformations
    {self._generate_grpc_response_transform_lua(grpc.response_transform)}

    local new_body = pb.encode("{grpc.response_type}", msg)
    body:setBytes(new_body)
end
'''

    return {
        "name": "envoy.filters.http.lua",
        "typed_config": {
            "@type": "type.googleapis.com/envoy.extensions.filters.http.lua.v3.Lua",
            "inline_code": lua_code
        }
    }
```

#### Nginx (OpenResty Lua)

**File:** `gal/providers/nginx.py`

```python
def _generate_grpc_transformation_nginx(self, route):
    """Generate Nginx/OpenResty Lua blocks for gRPC transformation."""
    if not route.grpc_transformation or not route.grpc_transformation.enabled:
        return []

    grpc = route.grpc_transformation
    proto_desc = self._get_proto_descriptor(grpc.proto_descriptor)

    output = []
    output.append("# gRPC Transformation (OpenResty)")
    output.append("")

    # Request transformation
    output.append("access_by_lua_block {")
    output.append("    local pb = require('pb')")
    output.append(f"    pb.loadfile('{proto_desc.path}')")
    output.append("")
    output.append("    -- Read gRPC message body")
    output.append("    ngx.req.read_body()")
    output.append("    local body = ngx.req.get_body_data()")
    output.append("")
    output.append(f"    -- Decode Protobuf message")
    output.append(f"    local msg = pb.decode('{grpc.request_type}', body)")
    output.append("")

    # Add fields
    if grpc.request_transform and grpc.request_transform.add_fields:
        output.append("    -- Add fields")
        for key, value in grpc.request_transform.add_fields.items():
            if value == "{{uuid}}":
                output.append(f"    msg['{key}'] = ngx.var.request_id")
            elif value in ["{{timestamp}}", "{{now}}"]:
                output.append(f"    msg['{key}'] = ngx.utctime()")
            else:
                output.append(f"    msg['{key}'] = '{value}'")
        output.append("")

    # Remove fields
    if grpc.request_transform and grpc.request_transform.remove_fields:
        output.append("    -- Remove fields")
        for field in grpc.request_transform.remove_fields:
            output.append(f"    msg['{field}'] = nil")
        output.append("")

    # Rename fields
    if grpc.request_transform and grpc.request_transform.rename_fields:
        output.append("    -- Rename fields")
        for old_name, new_name in grpc.request_transform.rename_fields.items():
            output.append(f"    msg['{new_name}'] = msg['{old_name}']")
            output.append(f"    msg['{old_name}'] = nil")
        output.append("")

    output.append(f"    -- Encode back to Protobuf")
    output.append(f"    local new_body = pb.encode('{grpc.request_type}', msg)")
    output.append("    ngx.req.set_body_data(new_body)")
    output.append("}")
    output.append("")

    # Response transformation
    if grpc.response_transform:
        output.append("body_filter_by_lua_block {")
        output.append("    local pb = require('pb')")
        output.append("")
        output.append("    local chunk = ngx.arg[1]")
        output.append("    local eof = ngx.arg[2]")
        output.append("")
        output.append("    if eof then")
        output.append(f"        local msg = pb.decode('{grpc.response_type}', chunk)")
        output.append("")

        # Filter fields
        if grpc.response_transform.filter_fields:
            output.append("        -- Filter sensitive fields")
            for field in grpc.response_transform.filter_fields:
                output.append(f"        msg['{field}'] = nil")
            output.append("")

        # Add fields
        if grpc.response_transform.add_fields:
            output.append("        -- Add metadata fields")
            for key, value in grpc.response_transform.add_fields.items():
                if value == "{{timestamp}}":
                    output.append(f"        msg['{key}'] = ngx.utctime()")
                else:
                    output.append(f"        msg['{key}'] = '{value}'")
            output.append("")

        output.append(f"        ngx.arg[1] = pb.encode('{grpc.response_type}', msg)")
        output.append("    end")
        output.append("}")

    return "\n".join(output)
```

#### Kong (Custom Plugin)

**File:** `gal/providers/kong.py`

```python
def _generate_grpc_transformation_kong(self, route):
    """Generate Kong plugin config for gRPC transformation."""
    if not route.grpc_transformation or not route.grpc_transformation.enabled:
        return None

    grpc = route.grpc_transformation

    logger.warning(
        "gRPC transformation in Kong requires custom plugin or grpc-gateway. "
        "Options:\n"
        "  1. Use Kong's grpc-gateway plugin: https://docs.konghq.com/hub/kong-inc/grpc-gateway/\n"
        "  2. Develop custom Kong plugin with lua-protobuf\n"
        "  3. Deploy external transformation service with Kong's request-transformer-advanced"
    )

    # Basic grpc-gateway config
    return {
        "name": "grpc-gateway",
        "config": {
            "proto": grpc.proto_descriptor,
            "service": grpc.service,
        }
    }
```

#### APISIX (grpc-transcode Plugin)

**File:** `gal/providers/apisix.py`

```python
def _generate_grpc_transformation_apisix(self, route):
    """Generate APISIX grpc-transcode plugin config."""
    if not route.grpc_transformation or not route.grpc_transformation.enabled:
        return {}

    grpc = route.grpc_transformation
    proto_desc = self._get_proto_descriptor(grpc.proto_descriptor)

    # APISIX grpc-transcode for gRPC ‚Üî REST
    # For pure gRPC transformation, use serverless-pre-function
    return {
        "serverless-pre-function": {
            "phase": "rewrite",
            "functions": [
                f"""
                return function(conf, ctx)
                    local pb = require("pb")
                    local core = require("apisix.core")

                    -- Load proto descriptor
                    pb.loadfile("{proto_desc.path}")

                    -- Get request body
                    local body = core.request.get_body()
                    local msg = pb.decode("{grpc.request_type}", body)

                    -- Apply transformations
                    {self._generate_grpc_transform_lua(grpc.request_transform)}

                    -- Encode back
                    local new_body = pb.encode("{grpc.request_type}", msg)
                    ngx.req.set_body_data(new_body)
                end
                """
            ]
        }
    }
```

#### HAProxy (Lua Script)

**File:** `gal/providers/haproxy.py`

```python
def _generate_grpc_transformation_haproxy(self, route):
    """Generate HAProxy Lua script reference for gRPC transformation."""
    if not route.grpc_transformation or not route.grpc_transformation.enabled:
        return []

    grpc = route.grpc_transformation

    logger.warning(
        "gRPC transformation in HAProxy requires external Lua scripts. "
        "Steps:\n"
        "  1. Install lua-protobuf: luarocks install lua-protobuf\n"
        "  2. Create Lua script: /etc/haproxy/lua/grpc_transform.lua\n"
        "  3. Load in global section: lua-load /etc/haproxy/lua/grpc_transform.lua\n"
        "  4. Reference in backend: http-request lua.grpc_transform"
    )

    output = []
    output.append(f"    # gRPC Transformation (requires Lua script)")
    output.append(f"    http-request lua.grpc_transform_{grpc.service}")
    output.append(f"    http-response lua.grpc_transform_response_{grpc.service}")

    return output
```

#### Traefik (Middleware Warning)

**File:** `gal/providers/traefik.py`

```python
def _generate_grpc_transformation_traefik(self, route):
    """Traefik gRPC transformation warning."""
    if not route.grpc_transformation or not route.grpc_transformation.enabled:
        return None

    logger.warning(
        "gRPC transformation is not natively supported by Traefik. "
        "Alternatives:\n"
        "  1. ForwardAuth middleware with external gRPC transformation service\n"
        "  2. Custom Traefik plugin (Go development required)\n"
        "  3. Use alternative provider: Envoy, Kong, APISIX, Nginx, HAProxy"
    )

    return None
```

### Proto Descriptor Management

**File:** `gal/proto_manager.py` (NEW)

```python
import os
import subprocess
from typing import Dict, Optional
from gal.config import ProtoDescriptor

class ProtoManager:
    """Manages Protobuf descriptors for gRPC transformations."""

    def __init__(self, proto_dir: str = "/etc/gal/protos"):
        self.proto_dir = proto_dir
        self.descriptors: Dict[str, ProtoDescriptor] = {}
        os.makedirs(proto_dir, exist_ok=True)

    def register_descriptor(self, descriptor: ProtoDescriptor):
        """Register a proto descriptor."""
        self.descriptors[descriptor.name] = descriptor

        if descriptor.source == "file":
            # File already exists, validate
            if not os.path.exists(descriptor.path):
                raise FileNotFoundError(f"Proto descriptor not found: {descriptor.path}")

        elif descriptor.source == "inline":
            # Write inline proto content to file
            proto_file = os.path.join(self.proto_dir, f"{descriptor.name}.proto")
            with open(proto_file, 'w') as f:
                f.write(descriptor.content)

            # Compile to .desc
            descriptor.path = self._compile_proto(proto_file)

        elif descriptor.source == "url":
            # Download proto file from URL
            proto_file = self._download_proto(descriptor.url, descriptor.name)
            descriptor.path = self._compile_proto(proto_file)

    def _compile_proto(self, proto_file: str) -> str:
        """Compile .proto to .desc using protoc."""
        desc_file = proto_file.replace(".proto", ".desc")

        result = subprocess.run([
            "protoc",
            f"--descriptor_set_out={desc_file}",
            f"--proto_path={self.proto_dir}",
            proto_file
        ], capture_output=True, text=True)

        if result.returncode != 0:
            raise RuntimeError(f"protoc compilation failed: {result.stderr}")

        return desc_file

    def _download_proto(self, url: str, name: str) -> str:
        """Download proto file from URL."""
        import requests

        proto_file = os.path.join(self.proto_dir, f"{name}.proto")
        response = requests.get(url)
        response.raise_for_status()

        with open(proto_file, 'wb') as f:
            f.write(response.content)

        return proto_file

    def get_descriptor(self, name: str) -> Optional[ProtoDescriptor]:
        """Get registered proto descriptor by name."""
        return self.descriptors.get(name)
```

### Testing Strategy

**File:** `tests/test_grpc_transformation.py` (15+ tests)

```python
# Test categories:
# 1. Config model tests (GrpcTransformation, ProtoDescriptor)
# 2. YAML parsing tests
# 3. Proto descriptor management tests
# 4. Provider-specific tests (Envoy, Kong, APISIX, Nginx, HAProxy, Traefik)
# 5. Integration tests with real proto files
```

### Documentation

**File:** `docs/guides/GRPC_TRANSFORMATIONS.md` (1000+ lines, German)

Sections:
- √úbersicht & Use Cases
- Schnellstart (3 Beispiele)
- Proto Descriptor Management
- Configuration Options
- Provider-Implementierungen (alle 6)
- Deployment Strategies (Volume Mounts, ConfigMaps)
- Best Practices
- Troubleshooting

**File:** `examples/grpc-transformation-example.yaml` (10+ scenarios)

### Milestones

**Week 1-2:** Config Model + Proto Manager
- GrpcTransformation, ProtoDescriptor models
- ProtoManager implementation
- YAML parsing
- 5+ config tests

**Week 2-3:** Provider Implementations
- Envoy (Lua filter)
- Nginx (OpenResty Lua)
- APISIX (Serverless Lua)
- Kong (Plugin warning)
- HAProxy (Lua reference)
- Traefik (Limitation warning)
- 10+ provider tests

**Week 3-4:** Documentation & Examples
- docs/guides/GRPC_TRANSFORMATIONS.md
- examples/grpc-transformation-example.yaml
- README.md updates
- ROADMAP.md updates

### Acceptance Criteria

‚úÖ GrpcTransformation config model implemented
‚úÖ ProtoManager can load/compile .proto files
‚úÖ Envoy generates valid Lua filter for gRPC
‚úÖ Nginx generates valid OpenResty Lua blocks
‚úÖ APISIX generates serverless-pre-function config
‚úÖ Kong shows helpful warning + alternatives
‚úÖ HAProxy shows Lua script setup instructions
‚úÖ Traefik shows limitation warning + alternatives
‚úÖ 15+ tests passing
‚úÖ 1000+ lines German documentation
‚úÖ 10+ example scenarios

---

## Feature 2-8: Other v1.4.0 Features

*(To be detailed in future updates)*

**Cloud Provider Support:**
- AWS API Gateway
- Azure API Management
- Google Cloud API Gateway

**Advanced Traffic Management:**
- A/B Testing & Traffic Splitting
- Request Mirroring/Shadowing
- Advanced Routing (Headers, JWT, Geo)

**GraphQL Support:**
- Schema Validation
- Query Complexity Limits

---

## Timeline

- **Month 1 (Weeks 1-4):** gRPC Transformations Feature
- **Month 2 (Weeks 5-8):** AWS API Gateway Provider
- **Month 3 (Weeks 9-12):** Azure API Management Provider
- **Month 4 (Weeks 13-16):** Google Cloud API Gateway + A/B Testing
- **Month 5 (Weeks 17-20):** Request Mirroring + Advanced Routing
- **Month 6 (Weeks 21-24):** GraphQL Support + Testing + Documentation

**Total:** 6 months (Q3 2026)

---

## Dependencies

- **protoc** (Protobuf Compiler) - for .proto ‚Üí .desc compilation
- **lua-protobuf** (Envoy, Nginx, APISIX, HAProxy) - Lua Protobuf library
- **requests** (Python) - for downloading proto files from URLs

---

## Next Steps (After v1.3.0 Completion)

1. Review gRPC Transformations requirements with users
2. Finalize Config Model design
3. Prototype Envoy + Nginx implementations
4. Begin implementation in Q2 2026

---

**Status:** üìù Planning Document - Ready for v1.4.0 Implementation
