# v1.4.0 Implementierungsplan

**Status:** üîÑ Konzept
**Zeitplan:** Q3 2026 (gesch√§tzt)
**Fokus:** Advanced Traffic Management & Multi-Cloud + gRPC Transformations

---

## Mission

**"Bringe gRPC zu GAL mit nahtlosen Protobuf-Transformationen √ºber alle Provider hinweg."**

Erm√∂gliche Benutzern die Transformation von gRPC Request/Response-Nachrichten mithilfe von Protobuf-Descriptors und mache gRPC-Services genauso einfach verwaltbar wie REST-APIs mit GALs provider-agnostischer Konfiguration.

---

## Feature-√úbersicht

| Feature | Status | Aufwand | Priorit√§t |
|---------|--------|---------|-----------|
| **1. gRPC Transformations** | üîÑ Ausstehend | 3-4 Wochen | üî¥ Hoch |
| **2. Cloud Provider Support (AWS)** | üîÑ Ausstehend | 4 Wochen | üü° Mittel |
| **3. Cloud Provider Support (Azure)** | üîÑ Ausstehend | 3 Wochen | üü° Mittel |
| **4. Cloud Provider Support (GCP)** | üîÑ Ausstehend | 3 Wochen | üü° Mittel |
| **5. A/B Testing & Traffic Splitting** | üîÑ Ausstehend | 2 Wochen | üü° Mittel |
| **6. Request Mirroring/Shadowing** | üîÑ Ausstehend | 2 Wochen | üü¢ Niedrig |
| **7. Advanced Routing** | üîÑ Ausstehend | 2 Wochen | üü¢ Niedrig |
| **8. GraphQL Support** | üîÑ Ausstehend | 3 Wochen | üü¢ Niedrig |

**Gesamtaufwand:** ~22-24 Wochen (5-6 Monate)
**Fortschritt:** 0/8 Features (0%)

---

## Feature 1: gRPC Transformations (DETAILLIERT)

**Status:** üîÑ Ausstehend
**Priorit√§t:** üî¥ Hoch
**Aufwand:** 3-4 Wochen

### Motivation

- **Problem**: gRPC-Services ben√∂tigen Body-Transformationen (Trace-IDs hinzuf√ºgen, Secrets entfernen, Felder umbenennen) genau wie REST-APIs
- **Herausforderung**: Jeder Provider hat unterschiedliche Mechanismen f√ºr Protobuf-Handling
- **L√∂sung**: GAL bietet eine einheitliche Konfiguration f√ºr gRPC-Transformationen mit Proto-Descriptor-Management

### Konfigurationsmodell

```python
# gal/config.py

@dataclass
class ProtoDescriptor:
    """Protobuf-Descriptor-Konfiguration."""
    name: str                    # Descriptor-Name (z.B. "user_service")
    source: str                  # "file", "inline", "url"
    path: str = ""               # Pfad zur .proto oder .desc Datei
    content: str = ""            # Inline Proto-Definition
    url: str = ""                # URL zum Download der Proto-Datei

@dataclass
class GrpcTransformation:
    """gRPC Transformation Konfiguration."""
    enabled: bool = True
    proto_descriptor: str = ""   # Referenz zum ProtoDescriptor-Namen
    package: str = ""            # Protobuf-Package (z.B. "user.v1")
    service: str = ""            # Service-Name (z.B. "UserService")
    request_type: str = ""       # Message-Type (z.B. "CreateUserRequest")
    response_type: str = ""      # Message-Type (z.B. "CreateUserResponse")

    # Transformationsregeln (wiederverwenden der bestehenden Body Transformation)
    request_transform: Optional[RequestBodyTransformation] = None
    response_transform: Optional[ResponseBodyTransformation] = None

@dataclass
class Route:
    # ... bestehende Felder ...
    grpc_transformation: Optional[GrpcTransformation] = None

@dataclass
class Config:
    # ... bestehende Felder ...
    proto_descriptors: List[ProtoDescriptor] = field(default_factory=list)
```

### YAML-Konfigurationsbeispiel

```yaml
# Proto Descriptors (global)
proto_descriptors:
  - name: user_service_proto
    source: file
    path: /etc/gal/protos/user.desc

  - name: order_service_proto
    source: inline
    content: |
      syntax = "proto3";
      package order.v1;

      service OrderService {
        rpc CreateOrder(CreateOrderRequest) returns (CreateOrderResponse);
      }

      message CreateOrderRequest {
        string user_id = 1;
        repeated string product_ids = 2;
      }

# Services
services:
  - name: user_grpc_service
    protocol: grpc
    upstream:
      host: user-grpc-backend
      port: 50051

    routes:
      - path_prefix: /user.v1.UserService/CreateUser
        grpc_transformation:
          enabled: true
          proto_descriptor: user_service_proto
          package: user.v1
          service: UserService
          request_type: CreateUserRequest
          response_type: CreateUserResponse

          request_transform:
            add_fields:
              trace_id: "{{uuid}}"
              timestamp: "{{timestamp}}"
              gateway_version: "GAL-v1.4.0"
            remove_fields:
              - internal_secret
              - debug_info
            rename_fields:
              user_id: userId
              email_address: email

          response_transform:
            filter_fields:
              - password_hash
              - internal_id
            add_fields:
              server_time: "{{timestamp}}"
              server_id: "gateway-01"
```

### Provider-Implementierungen

#### Envoy (Lua Filter)

**Datei:** `gal/providers/envoy.py`

```python
def _generate_grpc_transformation_envoy(self, route):
    """Generiere Envoy Lua Filter f√ºr gRPC Transformation."""
    if not route.grpc_transformation or not route.grpc_transformation.enabled:
        return None

    grpc = route.grpc_transformation
    proto_desc = self._get_proto_descriptor(grpc.proto_descriptor)

    lua_code = f'''
function envoy_on_request(request_handle)
    local pb = require("pb")

    -- Proto Descriptor laden (einmal pro Worker)
    if not _proto_loaded then
        pb.loadfile("{proto_desc.path}")
        _proto_loaded = true
    end

    -- gRPC Message Body abrufen
    local body = request_handle:body()
    if not body then
        return
    end

    -- Protobuf Message dekodieren
    local msg = pb.decode("{grpc.request_type}", body:getBytes(0, body:length()))

    -- Transformationen anwenden
    {self._generate_grpc_request_transform_lua(grpc.request_transform)}

    -- Zur√ºck zu Protobuf enkodieren
    local new_body = pb.encode("{grpc.request_type}", msg)
    body:setBytes(new_body)
end

function envoy_on_response(response_handle)
    local pb = require("pb")

    local body = response_handle:body()
    if not body then
        return
    end

    local msg = pb.decode("{grpc.response_type}", body:getBytes(0, body:length()))

    -- Response-Transformationen anwenden
    {self._generate_grpc_response_transform_lua(grpc.response_transform)}

    local new_body = pb.encode("{grpc.response_type}", msg)
    body:setBytes(new_body)
end
'''

    return {
        "name": "envoy.filters.http.lua",
        "typed_config": {
            "@type": "type.googleapis.com/envoy.extensions.filters.http.lua.v3.Lua",
            "inline_code": lua_code
        }
    }
```

#### Nginx (OpenResty Lua)

**Datei:** `gal/providers/nginx.py`

```python
def _generate_grpc_transformation_nginx(self, route):
    """Generiere Nginx/OpenResty Lua-Bl√∂cke f√ºr gRPC Transformation."""
    if not route.grpc_transformation or not route.grpc_transformation.enabled:
        return []

    grpc = route.grpc_transformation
    proto_desc = self._get_proto_descriptor(grpc.proto_descriptor)

    output = []
    output.append("# gRPC Transformation (OpenResty)")
    output.append("")

    # Request-Transformation
    output.append("access_by_lua_block {")
    output.append("    local pb = require('pb')")
    output.append(f"    pb.loadfile('{proto_desc.path}')")
    output.append("")
    output.append("    -- gRPC Message Body lesen")
    output.append("    ngx.req.read_body()")
    output.append("    local body = ngx.req.get_body_data()")
    output.append("")
    output.append(f"    -- Protobuf Message dekodieren")
    output.append(f"    local msg = pb.decode('{grpc.request_type}', body)")
    output.append("")

    # Felder hinzuf√ºgen
    if grpc.request_transform and grpc.request_transform.add_fields:
        output.append("    -- Felder hinzuf√ºgen")
        for key, value in grpc.request_transform.add_fields.items():
            if value == "{{uuid}}":
                output.append(f"    msg['{key}'] = ngx.var.request_id")
            elif value in ["{{timestamp}}", "{{now}}"]:
                output.append(f"    msg['{key}'] = ngx.utctime()")
            else:
                output.append(f"    msg['{key}'] = '{value}'")
        output.append("")

    # Felder entfernen
    if grpc.request_transform and grpc.request_transform.remove_fields:
        output.append("    -- Felder entfernen")
        for field in grpc.request_transform.remove_fields:
            output.append(f"    msg['{field}'] = nil")
        output.append("")

    # Felder umbenennen
    if grpc.request_transform and grpc.request_transform.rename_fields:
        output.append("    -- Felder umbenennen")
        for old_name, new_name in grpc.request_transform.rename_fields.items():
            output.append(f"    msg['{new_name}'] = msg['{old_name}']")
            output.append(f"    msg['{old_name}'] = nil")
        output.append("")

    output.append(f"    -- Zur√ºck zu Protobuf enkodieren")
    output.append(f"    local new_body = pb.encode('{grpc.request_type}', msg)")
    output.append("    ngx.req.set_body_data(new_body)")
    output.append("}")
    output.append("")

    # Response-Transformation
    if grpc.response_transform:
        output.append("body_filter_by_lua_block {")
        output.append("    local pb = require('pb')")
        output.append("")
        output.append("    local chunk = ngx.arg[1]")
        output.append("    local eof = ngx.arg[2]")
        output.append("")
        output.append("    if eof then")
        output.append(f"        local msg = pb.decode('{grpc.response_type}', chunk)")
        output.append("")

        # Felder filtern
        if grpc.response_transform.filter_fields:
            output.append("        -- Sensible Felder filtern")
            for field in grpc.response_transform.filter_fields:
                output.append(f"        msg['{field}'] = nil")
            output.append("")

        # Felder hinzuf√ºgen
        if grpc.response_transform.add_fields:
            output.append("        -- Metadaten-Felder hinzuf√ºgen")
            for key, value in grpc.response_transform.add_fields.items():
                if value == "{{timestamp}}":
                    output.append(f"        msg['{key}'] = ngx.utctime()")
                else:
                    output.append(f"        msg['{key}'] = '{value}'")
            output.append("")

        output.append(f"        ngx.arg[1] = pb.encode('{grpc.response_type}', msg)")
        output.append("    end")
        output.append("}")

    return "\n".join(output)
```

#### Kong (Custom Plugin)

**Datei:** `gal/providers/kong.py`

```python
def _generate_grpc_transformation_kong(self, route):
    """Generiere Kong Plugin Config f√ºr gRPC Transformation."""
    if not route.grpc_transformation or not route.grpc_transformation.enabled:
        return None

    grpc = route.grpc_transformation

    logger.warning(
        "gRPC Transformation in Kong erfordert ein Custom Plugin oder grpc-gateway. "
        "Optionen:\n"
        "  1. Nutze Kongs grpc-gateway Plugin: https://docs.konghq.com/hub/kong-inc/grpc-gateway/\n"
        "  2. Entwickle ein Custom Kong Plugin mit lua-protobuf\n"
        "  3. Deploye einen externen Transformation Service mit Kongs request-transformer-advanced"
    )

    # Basis grpc-gateway Config
    return {
        "name": "grpc-gateway",
        "config": {
            "proto": grpc.proto_descriptor,
            "service": grpc.service,
        }
    }
```

#### APISIX (grpc-transcode Plugin)

**Datei:** `gal/providers/apisix.py`

```python
def _generate_grpc_transformation_apisix(self, route):
    """Generiere APISIX grpc-transcode Plugin Config."""
    if not route.grpc_transformation or not route.grpc_transformation.enabled:
        return {}

    grpc = route.grpc_transformation
    proto_desc = self._get_proto_descriptor(grpc.proto_descriptor)

    # APISIX grpc-transcode f√ºr gRPC ‚Üî REST
    # F√ºr reine gRPC Transformation: serverless-pre-function verwenden
    return {
        "serverless-pre-function": {
            "phase": "rewrite",
            "functions": [
                f"""
                return function(conf, ctx)
                    local pb = require("pb")
                    local core = require("apisix.core")

                    -- Proto Descriptor laden
                    pb.loadfile("{proto_desc.path}")

                    -- Request Body abrufen
                    local body = core.request.get_body()
                    local msg = pb.decode("{grpc.request_type}", body)

                    -- Transformationen anwenden
                    {self._generate_grpc_transform_lua(grpc.request_transform)}

                    -- Zur√ºck enkodieren
                    local new_body = pb.encode("{grpc.request_type}", msg)
                    ngx.req.set_body_data(new_body)
                end
                """
            ]
        }
    }
```

#### HAProxy (Lua Script)

**Datei:** `gal/providers/haproxy.py`

```python
def _generate_grpc_transformation_haproxy(self, route):
    """Generiere HAProxy Lua Script Referenz f√ºr gRPC Transformation."""
    if not route.grpc_transformation or not route.grpc_transformation.enabled:
        return []

    grpc = route.grpc_transformation

    logger.warning(
        "gRPC Transformation in HAProxy erfordert externe Lua-Scripts. "
        "Schritte:\n"
        "  1. lua-protobuf installieren: luarocks install lua-protobuf\n"
        "  2. Lua-Script erstellen: /etc/haproxy/lua/grpc_transform.lua\n"
        "  3. In global section laden: lua-load /etc/haproxy/lua/grpc_transform.lua\n"
        "  4. Im Backend referenzieren: http-request lua.grpc_transform"
    )

    output = []
    output.append(f"    # gRPC Transformation (erfordert Lua-Script)")
    output.append(f"    http-request lua.grpc_transform_{grpc.service}")
    output.append(f"    http-response lua.grpc_transform_response_{grpc.service}")

    return output
```

#### Traefik (Middleware Warning)

**Datei:** `gal/providers/traefik.py`

```python
def _generate_grpc_transformation_traefik(self, route):
    """Traefik gRPC Transformation Warnung."""
    if not route.grpc_transformation or not route.grpc_transformation.enabled:
        return None

    logger.warning(
        "gRPC Transformation wird von Traefik nicht nativ unterst√ºtzt. "
        "Alternativen:\n"
        "  1. ForwardAuth Middleware mit externem gRPC Transformation Service\n"
        "  2. Custom Traefik Plugin (Go-Entwicklung erforderlich)\n"
        "  3. Alternativen Provider verwenden: Envoy, Kong, APISIX, Nginx, HAProxy"
    )

    return None
```

### Proto Descriptor Management

**Datei:** `gal/proto_manager.py` (NEU)

```python
import os
import subprocess
from typing import Dict, Optional
from gal.config import ProtoDescriptor

class ProtoManager:
    """Verwaltet Protobuf-Descriptors f√ºr gRPC-Transformationen."""

    def __init__(self, proto_dir: str = "/etc/gal/protos"):
        self.proto_dir = proto_dir
        self.descriptors: Dict[str, ProtoDescriptor] = {}
        os.makedirs(proto_dir, exist_ok=True)

    def register_descriptor(self, descriptor: ProtoDescriptor):
        """Registriere einen Proto-Descriptor."""
        self.descriptors[descriptor.name] = descriptor

        if descriptor.source == "file":
            # Datei existiert bereits, validieren
            if not os.path.exists(descriptor.path):
                raise FileNotFoundError(f"Proto Descriptor nicht gefunden: {descriptor.path}")

        elif descriptor.source == "inline":
            # Inline Proto-Content in Datei schreiben
            proto_file = os.path.join(self.proto_dir, f"{descriptor.name}.proto")
            with open(proto_file, 'w') as f:
                f.write(descriptor.content)

            # Zu .desc kompilieren
            descriptor.path = self._compile_proto(proto_file)

        elif descriptor.source == "url":
            # Proto-Datei von URL herunterladen
            proto_file = self._download_proto(descriptor.url, descriptor.name)
            descriptor.path = self._compile_proto(proto_file)

    def _compile_proto(self, proto_file: str) -> str:
        """Kompiliere .proto zu .desc mit protoc."""
        desc_file = proto_file.replace(".proto", ".desc")

        result = subprocess.run([
            "protoc",
            f"--descriptor_set_out={desc_file}",
            f"--proto_path={self.proto_dir}",
            proto_file
        ], capture_output=True, text=True)

        if result.returncode != 0:
            raise RuntimeError(f"protoc Kompilierung fehlgeschlagen: {result.stderr}")

        return desc_file

    def _download_proto(self, url: str, name: str) -> str:
        """Proto-Datei von URL herunterladen."""
        import requests

        proto_file = os.path.join(self.proto_dir, f"{name}.proto")
        response = requests.get(url)
        response.raise_for_status()

        with open(proto_file, 'wb') as f:
            f.write(response.content)

        return proto_file

    def get_descriptor(self, name: str) -> Optional[ProtoDescriptor]:
        """Registrierten Proto-Descriptor nach Namen abrufen."""
        return self.descriptors.get(name)
```

### Test-Strategie

**Datei:** `tests/test_grpc_transformation.py` (15+ Tests)

```python
# Test-Kategorien:
# 1. Config-Model-Tests (GrpcTransformation, ProtoDescriptor)
# 2. YAML-Parsing-Tests
# 3. Proto-Descriptor-Management-Tests
# 4. Provider-spezifische Tests (Envoy, Kong, APISIX, Nginx, HAProxy, Traefik)
# 5. Integrationstests mit echten Proto-Dateien
```

### Dokumentation

**Datei:** `docs/guides/GRPC_TRANSFORMATIONS.md` (1000+ Zeilen, Deutsch)

Abschnitte:
- √úbersicht & Anwendungsf√§lle
- Schnellstart (3 Beispiele)
- Proto Descriptor Management
- Konfigurationsoptionen
- Provider-Implementierungen (alle 6)
- Deployment-Strategien (Volume Mounts, ConfigMaps)
- Best Practices
- Troubleshooting

**Datei:** `examples/grpc-transformation-example.yaml` (10+ Szenarien)

### Meilensteine

**Woche 1-2:** Config Model + Proto Manager
- GrpcTransformation, ProtoDescriptor Models
- ProtoManager Implementierung
- YAML-Parsing
- 5+ Config-Tests

**Woche 2-3:** Provider-Implementierungen
- Envoy (Lua Filter)
- Nginx (OpenResty Lua)
- APISIX (Serverless Lua)
- Kong (Plugin-Warnung)
- HAProxy (Lua-Referenz)
- Traefik (Einschr√§nkungs-Warnung)
- 10+ Provider-Tests

**Woche 3-4:** Dokumentation & Beispiele
- docs/guides/GRPC_TRANSFORMATIONS.md
- examples/grpc-transformation-example.yaml
- README.md Updates
- ROADMAP.md Updates

### Akzeptanzkriterien

‚úÖ GrpcTransformation Config-Model implementiert
‚úÖ ProtoManager kann .proto-Dateien laden/kompilieren
‚úÖ Envoy generiert validen Lua-Filter f√ºr gRPC
‚úÖ Nginx generiert valide OpenResty Lua-Bl√∂cke
‚úÖ APISIX generiert serverless-pre-function Config
‚úÖ Kong zeigt hilfreiche Warnung + Alternativen
‚úÖ HAProxy zeigt Lua-Script-Setup-Anweisungen
‚úÖ Traefik zeigt Einschr√§nkungs-Warnung + Alternativen
‚úÖ 15+ Tests bestehen
‚úÖ 1000+ Zeilen deutsche Dokumentation
‚úÖ 10+ Beispiel-Szenarien

---

## Feature 2: Cloud Provider Support (AWS) - AWS API Gateway

**Status:** üîÑ Ausstehend
**Priorit√§t:** üü° Mittel
**Aufwand:** 4 Wochen

*(Wird in zuk√ºnftigen Updates detailliert)*

**Geplante Features:**
- AWS API Gateway REST API
- API Gateway v2 (HTTP API)
- Lambda Integration
- VPC Links
- Cognito Authorizers
- Usage Plans & API Keys

---

## Feature 3: Cloud Provider Support (Azure) - Azure API Management (DETAILLIERT)

**Status:** üîÑ Ausstehend
**Priorit√§t:** üü° Mittel
**Aufwand:** 3 Wochen

### Motivation

- **Problem**: Azure-Kunden ben√∂tigen Azure API Management (APIM) Integration f√ºr Cloud-Native Deployments
- **Herausforderung**: Azure APIM verwendet XML-basierte Policies und ARM-Templates
- **L√∂sung**: GAL generiert Azure APIM Policies und ARM-Templates aus einheitlicher YAML-Konfiguration

### Warum Azure API Management?

**Vorteile:**
- ‚úÖ **Fully Managed**: Keine Server-Wartung erforderlich
- ‚úÖ **Azure Integration**: Native Integration mit Azure AD, Key Vault, App Services
- ‚úÖ **Developer Portal**: Automatisch generierte API-Dokumentation
- ‚úÖ **Subscription Keys**: Built-in API Key Management
- ‚úÖ **OpenAPI Support**: Import/Export von OpenAPI/Swagger Specs
- ‚úÖ **Multi-Region**: Global Deployment mit Azure Traffic Manager
- ‚úÖ **Monitoring**: Azure Monitor, Application Insights Integration

**Use Cases:**
- Azure Cloud-Native Applications
- Enterprise API Gateways (Azure Stack)
- Hybrid Cloud (On-Premises + Azure)
- API Monetization (Subscription Management)
- Developer Portals

### Azure APIM Hierarchie

```
Azure APIM
  ‚îú‚îÄ‚îÄ Products (z.B. "Starter", "Premium")
  ‚îÇ   ‚îú‚îÄ‚îÄ APIs
  ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Operations (Endpoints)
  ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Policies (Inbound, Backend, Outbound, On-Error)
  ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Request/Response Schemas
  ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ API-Level Policies
  ‚îÇ   ‚îî‚îÄ‚îÄ Product-Level Policies
  ‚îú‚îÄ‚îÄ Backends (Upstream Targets)
  ‚îú‚îÄ‚îÄ Named Values (Configuration Variables)
  ‚îî‚îÄ‚îÄ Subscriptions (API Keys)
```

### Konfigurationsmodell

```python
# gal/config.py

@dataclass
class AzureAPIMConfig:
    """Azure API Management spezifische Konfiguration."""
    product_name: str = "GAL-Product"
    product_description: str = "API Product managed by GAL"
    product_published: bool = True
    product_subscription_required: bool = True

    # Azure-specific settings
    api_revision: str = "1"
    api_version: Optional[str] = None
    api_version_set_id: Optional[str] = None

    # OpenAPI Export
    openapi_export: bool = True
    openapi_version: str = "3.0.0"

    # Subscription Keys
    subscription_keys_required: bool = True

    # Rate Limiting (APIM-style)
    rate_limit_calls: int = 100
    rate_limit_renewal_period: int = 60  # seconds

@dataclass
class Service:
    # ... existing fields ...
    azure_apim: Optional[AzureAPIMConfig] = None
```

### YAML-Konfigurationsbeispiel

```yaml
version: "1.0"
provider: azure_apim

# Azure APIM Global Config
global_config:
  azure_apim:
    resource_group: "gal-resource-group"
    apim_service_name: "gal-apim-service"
    location: "westeurope"
    sku: "Developer"  # Developer, Basic, Standard, Premium

services:
  - name: user_api
    protocol: http

    # Azure APIM Product Configuration
    azure_apim:
      product_name: "UserAPI-Product"
      product_description: "User Management API"
      product_published: true
      product_subscription_required: true
      api_revision: "1"
      api_version: "v1"
      openapi_export: true
      rate_limit_calls: 1000
      rate_limit_renewal_period: 60

    upstream:
      targets:
        - host: backend.example.com
          port: 443
      load_balancer:
        algorithm: round_robin

    routes:
      - path_prefix: /api/users
        http_methods: ["GET", "POST"]

        # Rate Limiting (wird zu APIM rate-limit Policy)
        rate_limit:
          enabled: true
          requests_per_second: 100

        # Authentication (wird zu APIM validate-jwt Policy)
        authentication:
          type: jwt
          jwt_config:
            issuer: "https://login.microsoftonline.com/{tenant-id}/v2.0"
            audience: "api://user-api"
            required_claims:
              - name: "roles"
                value: "admin"

        # Caching (wird zu APIM cache-lookup/cache-store Policy)
        cache:
          enabled: true
          ttl: 300
          vary_by_query_params: ["id"]

        # Headers (wird zu APIM set-header Policy)
        headers:
          request_add:
            X-API-Version: "v1"
            X-Gateway: "GAL-Azure-APIM"
          response_add:
            X-Powered-By: "Azure API Management"
```

### Provider-Implementierung

**Datei:** `gal/providers/azure_apim.py` (NEU)

```python
import json
from typing import Dict, List, Any
from gal.config import Config, Service, Route
from gal.providers.base import Provider

class AzureAPIMProvider(Provider):
    """Azure API Management Provider f√ºr GAL."""

    def __init__(self):
        super().__init__("azure_apim")

    def generate(self, config: Config) -> str:
        """Generiere Azure APIM ARM Template."""
        arm_template = {
            "$schema": "https://schema.management.azure.com/schemas/2019-04-01/deploymentTemplate.json#",
            "contentVersion": "1.0.0.0",
            "parameters": {},
            "variables": {},
            "resources": []
        }

        # APIM Service (falls nicht existiert)
        apim_service = self._generate_apim_service(config)
        arm_template["resources"].append(apim_service)

        # APIs, Products, Policies
        for service in config.services:
            # API Resource
            api_resource = self._generate_api_resource(service)
            arm_template["resources"].append(api_resource)

            # Operations (Routes)
            for route in service.routes:
                operation = self._generate_operation(service, route)
                arm_template["resources"].append(operation)

                # Operation Policies
                policy = self._generate_operation_policy(service, route)
                arm_template["resources"].append(policy)

            # Product
            product = self._generate_product(service)
            arm_template["resources"].append(product)

            # Backend
            backend = self._generate_backend(service)
            arm_template["resources"].append(backend)

        return json.dumps(arm_template, indent=2)

    def _generate_apim_service(self, config: Config) -> Dict[str, Any]:
        """Generiere APIM Service Resource."""
        return {
            "type": "Microsoft.ApiManagement/service",
            "apiVersion": "2021-08-01",
            "name": config.global_config.azure_apim.apim_service_name,
            "location": config.global_config.azure_apim.location,
            "sku": {
                "name": config.global_config.azure_apim.sku,
                "capacity": 1
            },
            "properties": {
                "publisherEmail": "admin@example.com",
                "publisherName": "GAL Admin"
            }
        }

    def _generate_api_resource(self, service: Service) -> Dict[str, Any]:
        """Generiere API Resource."""
        apim = service.azure_apim or AzureAPIMConfig()

        return {
            "type": "Microsoft.ApiManagement/service/apis",
            "apiVersion": "2021-08-01",
            "name": f"[concat(parameters('apimServiceName'), '/{service.name}')]",
            "dependsOn": [
                "[resourceId('Microsoft.ApiManagement/service', parameters('apimServiceName'))]"
            ],
            "properties": {
                "displayName": service.name,
                "apiRevision": apim.api_revision,
                "apiVersion": apim.api_version,
                "subscriptionRequired": apim.subscription_keys_required,
                "path": service.name,
                "protocols": ["https"],
                "isCurrent": True
            }
        }

    def _generate_operation(self, service: Service, route: Route) -> Dict[str, Any]:
        """Generiere API Operation (Endpoint)."""
        operation_name = route.path_prefix.replace("/", "_").strip("_")

        return {
            "type": "Microsoft.ApiManagement/service/apis/operations",
            "apiVersion": "2021-08-01",
            "name": f"[concat(parameters('apimServiceName'), '/{service.name}/{operation_name}')]",
            "dependsOn": [
                f"[resourceId('Microsoft.ApiManagement/service/apis', parameters('apimServiceName'), '{service.name}')]"
            ],
            "properties": {
                "displayName": operation_name,
                "method": route.http_methods[0] if route.http_methods else "GET",
                "urlTemplate": route.path_prefix,
                "templateParameters": [],
                "responses": []
            }
        }

    def _generate_operation_policy(self, service: Service, route: Route) -> Dict[str, Any]:
        """Generiere Operation Policy (XML)."""
        operation_name = route.path_prefix.replace("/", "_").strip("_")
        policy_xml = self._build_policy_xml(service, route)

        return {
            "type": "Microsoft.ApiManagement/service/apis/operations/policies",
            "apiVersion": "2021-08-01",
            "name": f"[concat(parameters('apimServiceName'), '/{service.name}/{operation_name}/policy')]",
            "dependsOn": [
                f"[resourceId('Microsoft.ApiManagement/service/apis/operations', parameters('apimServiceName'), '{service.name}', '{operation_name}')]"
            ],
            "properties": {
                "value": policy_xml,
                "format": "xml"
            }
        }

    def _build_policy_xml(self, service: Service, route: Route) -> str:
        """Generiere Azure APIM Policy XML."""
        policies = ['<policies>']

        # Inbound Policies
        policies.append('    <inbound>')
        policies.append('        <base />')

        # Rate Limiting
        if route.rate_limit and route.rate_limit.enabled:
            policies.append(f'        <rate-limit calls="{route.rate_limit.requests_per_second * 60}" renewal-period="60" />')

        # JWT Validation
        if route.authentication and route.authentication.type == "jwt":
            jwt = route.authentication.jwt_config
            policies.append(f'        <validate-jwt header-name="Authorization" failed-validation-httpcode="401">')
            policies.append(f'            <openid-config url="{jwt.issuer}/.well-known/openid-configuration" />')
            policies.append(f'            <audiences>')
            policies.append(f'                <audience>{jwt.audience}</audience>')
            policies.append(f'            </audiences>')

            if jwt.required_claims:
                policies.append(f'            <required-claims>')
                for claim in jwt.required_claims:
                    policies.append(f'                <claim name="{claim.name}" match="any">')
                    policies.append(f'                    <value>{claim.value}</value>')
                    policies.append(f'                </claim>')
                policies.append(f'            </required-claims>')

            policies.append(f'        </validate-jwt>')

        # API Key Authentication
        elif route.authentication and route.authentication.type == "api_key":
            policies.append(f'        <check-header name="Ocp-Apim-Subscription-Key" failed-check-httpcode="401" />')

        # Header Manipulation
        if route.headers and route.headers.request_add:
            for key, value in route.headers.request_add.items():
                policies.append(f'        <set-header name="{key}" exists-action="override">')
                policies.append(f'            <value>{value}</value>')
                policies.append(f'        </set-header>')

        # Caching (Lookup)
        if route.cache and route.cache.enabled:
            vary_by = ' '.join([f'@(context.Request.Url.Query.GetValueOrDefault("{p}",""))'
                               for p in route.cache.vary_by_query_params])
            policies.append(f'        <cache-lookup vary-by-developer="false" vary-by-developer-groups="false">')
            if route.cache.vary_by_query_params:
                policies.append(f'            <vary-by-query-parameter>{",".join(route.cache.vary_by_query_params)}</vary-by-query-parameter>')
            policies.append(f'        </cache-lookup>')

        # Backend Service URL
        if service.upstream and service.upstream.targets:
            target = service.upstream.targets[0]
            backend_url = f"https://{target.host}:{target.port}"
            policies.append(f'        <set-backend-service base-url="{backend_url}" />')

        policies.append('    </inbound>')

        # Backend Policies
        policies.append('    <backend>')
        policies.append('        <base />')
        policies.append('    </backend>')

        # Outbound Policies
        policies.append('    <outbound>')
        policies.append('        <base />')

        # Response Headers
        if route.headers and route.headers.response_add:
            for key, value in route.headers.response_add.items():
                policies.append(f'        <set-header name="{key}" exists-action="override">')
                policies.append(f'            <value>{value}</value>')
                policies.append(f'        </set-header>')

        # Caching (Store)
        if route.cache and route.cache.enabled:
            policies.append(f'        <cache-store duration="{route.cache.ttl}" />')

        policies.append('    </outbound>')

        # On-Error Policies
        policies.append('    <on-error>')
        policies.append('        <base />')
        policies.append('    </on-error>')

        policies.append('</policies>')

        return '\n'.join(policies)

    def _generate_product(self, service: Service) -> Dict[str, Any]:
        """Generiere Product Resource."""
        apim = service.azure_apim or AzureAPIMConfig()

        return {
            "type": "Microsoft.ApiManagement/service/products",
            "apiVersion": "2021-08-01",
            "name": f"[concat(parameters('apimServiceName'), '/{apim.product_name}')]",
            "dependsOn": [
                "[resourceId('Microsoft.ApiManagement/service', parameters('apimServiceName'))]"
            ],
            "properties": {
                "displayName": apim.product_name,
                "description": apim.product_description,
                "subscriptionRequired": apim.product_subscription_required,
                "approvalRequired": False,
                "state": "published" if apim.product_published else "notPublished"
            }
        }

    def _generate_backend(self, service: Service) -> Dict[str, Any]:
        """Generiere Backend Resource."""
        if not service.upstream or not service.upstream.targets:
            return {}

        target = service.upstream.targets[0]

        return {
            "type": "Microsoft.ApiManagement/service/backends",
            "apiVersion": "2021-08-01",
            "name": f"[concat(parameters('apimServiceName'), '/{service.name}-backend')]",
            "dependsOn": [
                "[resourceId('Microsoft.ApiManagement/service', parameters('apimServiceName'))]"
            ],
            "properties": {
                "description": f"Backend for {service.name}",
                "url": f"https://{target.host}:{target.port}",
                "protocol": "http",
                "resourceId": ""
            }
        }
```

### OpenAPI Export

**Datei:** `gal/providers/azure_apim.py` (zus√§tzliche Methode)

```python
def generate_openapi(self, config: Config) -> str:
    """Generiere OpenAPI 3.0 Spec f√ºr Azure APIM Import."""
    openapi = {
        "openapi": "3.0.0",
        "info": {
            "title": "GAL API",
            "version": "1.0.0",
            "description": "Generated by GAL"
        },
        "servers": [],
        "paths": {},
        "components": {
            "securitySchemes": {}
        }
    }

    for service in config.services:
        for route in service.routes:
            path = route.path_prefix
            if path not in openapi["paths"]:
                openapi["paths"][path] = {}

            for method in (route.http_methods or ["get"]):
                openapi["paths"][path][method.lower()] = {
                    "summary": f"{method.upper()} {path}",
                    "operationId": f"{method.lower()}_{path.replace('/', '_')}",
                    "responses": {
                        "200": {
                            "description": "Successful response"
                        }
                    }
                }

                # Security
                if route.authentication:
                    if route.authentication.type == "jwt":
                        openapi["components"]["securitySchemes"]["oauth2"] = {
                            "type": "oauth2",
                            "flows": {
                                "implicit": {
                                    "authorizationUrl": route.authentication.jwt_config.issuer,
                                    "scopes": {}
                                }
                            }
                        }
                        openapi["paths"][path][method.lower()]["security"] = [{"oauth2": []}]

    return json.dumps(openapi, indent=2)
```

### Test-Strategie

**Datei:** `tests/test_azure_apim.py` (20+ Tests)

```python
# Test-Kategorien:
# 1. Provider basics (name, validate)
# 2. ARM Template generation
# 3. API Resource generation
# 4. Operation generation
# 5. Policy XML generation (rate-limit, validate-jwt, caching)
# 6. Product generation
# 7. Backend generation
# 8. OpenAPI export
# 9. Multi-service scenarios
# 10. Edge cases (missing configs)
```

### Dokumentation

**Datei:** `docs/guides/AZURE_APIM.md` (1000+ Zeilen, Deutsch)

Abschnitte:
- √úbersicht Azure API Management
- Schnellstart (3 Beispiele)
- Installation & Setup (Azure CLI, ARM Templates)
- Konfigurationsoptionen
- Policy-Typen (Inbound, Backend, Outbound, On-Error)
- Azure-spezifische Features:
  - Subscription Keys
  - Products & APIs
  - Developer Portal
  - Named Values
  - Azure AD Integration
  - Application Insights
- Deployment-Strategien (ARM, Terraform, Bicep)
- Best Practices
- Troubleshooting

**Datei:** `examples/azure-apim-example.yaml` (10+ Szenarien)

Szenarien:
1. Simple REST API mit Subscription Keys
2. JWT Authentication mit Azure AD
3. Rate Limiting mit APIM Policies
4. Caching mit Query Parameter Variations
5. Multiple Products (Starter, Premium)
6. Backend Load Balancing
7. CORS Policies
8. Request/Response Transformation
9. API Versioning (v1, v2)
10. Hybrid Cloud (On-Premises Backend)

### Meilensteine

**Woche 1:** Provider Implementation + ARM Templates
- AzureAPIMProvider Klasse
- ARM Template Generation
- API, Operation, Product Resources
- 10+ Tests

**Woche 2:** Policy Generation + OpenAPI
- Policy XML Generator (rate-limit, validate-jwt, caching, headers)
- OpenAPI 3.0 Export
- Backend Resource
- 10+ Tests

**Woche 3:** Documentation + Examples + Integration
- docs/guides/AZURE_APIM.md (1000+ Zeilen)
- examples/azure-apim-example.yaml (10+ Szenarien)
- CLI Integration
- README.md Updates
- Azure Deployment Guide

### Akzeptanzkriterien

‚úÖ AzureAPIMProvider generiert valide ARM Templates
‚úÖ API, Operation, Product, Backend Resources korrekt
‚úÖ Policy XML korrekt generiert (rate-limit, validate-jwt, caching)
‚úÖ OpenAPI 3.0 Export funktioniert
‚úÖ Subscription Keys Support
‚úÖ Azure AD JWT Validation
‚úÖ Header Manipulation (set-header Policy)
‚úÖ Caching (cache-lookup, cache-store Policies)
‚úÖ 20+ Tests bestehen (100% passing)
‚úÖ 1000+ Zeilen deutsche Dokumentation
‚úÖ 10+ Beispiel-Szenarien
‚úÖ Azure CLI Deployment-Guide

### Deployment-Beispiel

```bash
# GAL-Config ‚Üí Azure APIM ARM Template generieren
gal generate --config config.yaml --provider azure_apim --output azure-apim-template.json

# OpenAPI Spec generieren (f√ºr APIM Import)
gal generate --config config.yaml --provider azure_apim --format openapi --output openapi.json

# Azure CLI Deployment
az group create --name gal-resource-group --location westeurope

az deployment group create \
  --resource-group gal-resource-group \
  --template-file azure-apim-template.json

# Oder: OpenAPI Import in existierenden APIM Service
az apim api import \
  --resource-group gal-resource-group \
  --service-name gal-apim-service \
  --path /api \
  --specification-format OpenApi \
  --specification-path openapi.json
```

---

## Feature 4: Cloud Provider Support (GCP) - Google Cloud API Gateway

**Status:** üîÑ Ausstehend
**Priorit√§t:** üü° Mittel
**Aufwand:** 3 Wochen

*(Wird in zuk√ºnftigen Updates detailliert)*

**Geplante Features:**
- Google Cloud API Gateway
- OpenAPI 3.0 Integration
- Cloud Endpoints
- Service Account Authentication
- Cloud Logging & Monitoring
- GCP Load Balancer Integration

---

## Feature 5-8: Advanced Traffic Management & GraphQL

*(Werden in zuk√ºnftigen Updates detailliert)*

**Feature 5: A/B Testing & Traffic Splitting** (2 Wochen)
- Weight-based Traffic Splitting
- Header-based Routing
- Canary Deployments

**Feature 6: Request Mirroring/Shadowing** (2 Wochen)
- Traffic Mirroring (Shadow Traffic)
- Production Testing ohne User Impact

**Feature 7: Advanced Routing** (2 Wochen)
- Header-based Routing
- JWT Claims-based Routing
- Geo-based Routing

**Feature 8: GraphQL Support** (3 Wochen)
- GraphQL Schema Validation
- Query Complexity Limits
- GraphQL to REST Translation

---

## Zeitplan

- **Monat 1 (Wochen 1-4):** gRPC Transformations Feature
- **Monat 2 (Wochen 5-8):** AWS API Gateway Provider
- **Monat 3 (Wochen 9-12):** Azure API Management Provider
- **Monat 4 (Wochen 13-16):** Google Cloud API Gateway + A/B Testing
- **Monat 5 (Wochen 17-20):** Request Mirroring + Advanced Routing
- **Monat 6 (Wochen 21-24):** GraphQL Support + Testing + Dokumentation

**Gesamt:** 6 Monate (Q3 2026)

---

## Abh√§ngigkeiten

- **protoc** (Protobuf Compiler) - f√ºr .proto ‚Üí .desc Kompilierung
- **lua-protobuf** (Envoy, Nginx, APISIX, HAProxy) - Lua Protobuf-Bibliothek
- **requests** (Python) - zum Herunterladen von Proto-Dateien von URLs

---

## N√§chste Schritte (Nach v1.3.0 Abschluss)

1. gRPC Transformations Anforderungen mit Benutzern √ºberpr√ºfen
2. Config Model Design finalisieren
3. Envoy + Nginx Implementierungen prototypen
4. Implementation in Q2 2026 beginnen

---

**Status:** üìù Planungsdokument - Bereit f√ºr v1.4.0 Implementierung
