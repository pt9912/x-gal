# Request Mirroring Anleitung

**Umfassende Anleitung fÃ¼r Request Mirroring, Shadow Traffic und Production Testing in GAL (Gateway Abstraction Layer)**

## Inhaltsverzeichnis

1. [Ãœbersicht](#ubersicht)
2. [Schnellstart](#schnellstart)
3. [Konfigurationsoptionen](#konfigurationsoptionen)
4. [Provider-Implementierung](#provider-implementierung)
5. [HÃ¤ufige AnwendungsfÃ¤lle](#haufige-anwendungsfalle)
6. [Best Practices](#best-practices)
7. [Request Mirroring Testen](#request-mirroring-testen)
8. [Troubleshooting](#troubleshooting)

---

## Ãœbersicht

Request Mirroring (auch Shadow Traffic oder Dark Traffic genannt) ist ein essentielles Feature fÃ¼r sichere Production-Tests. GAL bietet eine einheitliche Request Mirroring-Konfiguration fÃ¼r alle unterstÃ¼tzten Gateway-Provider.

### Was ist Request Mirroring?

Request Mirroring dupliziert eingehende Requests und sendet sie an **Shadow Backends**, ohne die primÃ¤re Response zu beeinflussen. Dies ermÃ¶glicht Testing unter realer Last ohne Risiko fÃ¼r Produktions-Nutzer.

**Request Flow mit Mirroring**:

```
                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
Client Request â”€â”€â”€â”€â”€â”€â–ºâ”‚   API Gateway   â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                     â”‚
                    â–¼                     â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚ Primary Backend  â”‚  â”‚ Shadow Backend   â”‚
          â”‚   (Production)   â”‚  â”‚  (New Version)   â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚                      â”‚
                   â”‚                      â”‚ (ignored)
                   â–¼                      â–¼
          Response to Client         Logs/Metrics
```

### Warum ist Request Mirroring wichtig?

- âœ… **Sichere Production-Tests**: Neue Versionen mit echten Requests testen
- âœ… **Zero User Impact**: Shadow Traffic beeinflusst primÃ¤re Response nicht
- âœ… **Performance Validation**: Latenz und Throughput unter realer Last messen
- âœ… **Bug Detection**: Bugs finden, bevor Features live gehen
- âœ… **Data Collection**: Metriken und Logs von neuen Versionen sammeln
- âœ… **Gradual Rollout**: Schrittweise von 1% â†’ 100% Shadow Traffic erhÃ¶hen

### Provider-UnterstÃ¼tzung

| Feature | Envoy | Nginx | APISIX | HAProxy | Kong | Traefik | Azure APIM | AWS API GW | GCP API GW |
|---------|-------|-------|--------|---------|------|---------|------------|------------|------------|
| **Request Mirroring** | âœ… | âœ… | âœ… | âš ï¸ | âš ï¸ | âš ï¸ | âœ… | âš ï¸ | âš ï¸ |
| **Native Support** | âœ… | âœ… | âœ… | âš ï¸ | âŒ | âŒ | âœ… | âŒ | âŒ |
| **Sample Percentage** | âœ… | âœ… | âœ… | âœ… | âœ… | âš ï¸ | âœ… | âœ… | âœ… |
| **Custom Headers** | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… |
| **Multiple Mirrors** | âœ… | âœ… | âœ… | âœ… | âœ… | âš ï¸ | âœ… | âš ï¸ | âš ï¸ |
| **Fire-and-Forget** | âœ… | âœ… | âœ… | âœ… | âŒ | âš ï¸ | âœ… | âš ï¸ | âš ï¸ |
| **Setup KomplexitÃ¤t** | ğŸŸ¢ | ğŸŸ¢ | ğŸŸ¢ | ğŸ”´ | ğŸŸ¡ | ğŸŸ¡ | ğŸŸ¢ | ğŸŸ¡ | ğŸŸ¡ |

**Legende:**
- âœ… Native Support (eingebautes Feature)
- âš ï¸ Workaround/Externe Tools erforderlich (Plugin, Lambda, SPOE Agent)
- âŒ Nicht unterstÃ¼tzt
- ğŸŸ¢ Niedrige KomplexitÃ¤t | ğŸŸ¡ Mittlere KomplexitÃ¤t | ğŸ”´ Hohe KomplexitÃ¤t

**Wichtiger Hinweis fÃ¼r HAProxy:**
HAProxy unterstÃ¼tzt Request Mirroring Ã¼ber **SPOE (Stream Processing Offload Engine)** seit Version 2.0. Dies ist eine **native Funktion**, erfordert aber einen **externen SPOE Agent** (`spoa-mirror`).

**HAProxy Mirroring LÃ¶sungen (sortiert nach KomplexitÃ¤t):**
1. **SPOE + spoa-mirror** - Native HAProxy (seit 2.0), komplex, production-ready
2. **GoReplay (gor)** - Extern, einfach, empfohlen fÃ¼r Testing ([GitHub](https://github.com/buger/goreplay))
3. **Teeproxy** - Extern, einfach, synchron ([GitHub](https://github.com/chrissnell/teeproxy))
4. **Lua Scripting** - Custom, nicht fire-and-forget

Siehe [HAProxy Mirroring Dokumentation](#4-haproxy-ï¸-spoe-basiert---haproxy-20) und [E2E Tests](../../tests/docker/haproxy-mirroring/README.md) fÃ¼r Details.

---

## Schnellstart

### Minimale Konfiguration

```yaml
version: "1.0"
provider: gal

services:
  - name: api_service
    protocol: http
    upstream:
      targets:
        - host: api-v1.internal
          port: 8080

    routes:
      - path_prefix: /api/users
        methods: [GET, POST]

        # Request Mirroring aktivieren
        mirroring:
          enabled: true
          targets:
            - name: shadow-v2
              upstream:
                host: shadow-api-v2.internal
                port: 8080
              sample_percentage: 100.0  # 100% aller Requests
```

### Deployment

```bash
# Config generieren
gal generate --config config.yaml --provider envoy --output envoy.yaml

# Gateway starten
envoy -c envoy.yaml
```

### Verifikation

```bash
# Request an Primary Backend
curl http://localhost:8080/api/users

# Shadow Backend Logs prÃ¼fen
curl http://shadow-api-v2.internal:8080/metrics
```

---

## Konfigurationsoptionen

### MirroringConfig

```yaml
mirroring:
  enabled: true                    # Request Mirroring aktivieren
  mirror_request_body: true        # Body mitspiegeln (default: true)
  mirror_headers: true             # Headers mitspiegeln (default: true)
  targets:                         # Liste der Shadow Backends
    - name: shadow-v2              # Eindeutiger Name
      upstream:
        host: shadow-api-v2.internal
        port: 8080
      sample_percentage: 50.0      # 50% der Requests (0-100)
      timeout: "5s"                # Timeout fÃ¼r Shadow Requests
      headers:                     # Custom Headers fÃ¼r Shadow
        X-Mirror: "true"
        X-Shadow-Version: "v2"
```

### Parameter-Referenz

| Parameter | Typ | Default | Beschreibung |
|-----------|-----|---------|--------------|
| `enabled` | boolean | false | Request Mirroring aktivieren |
| `mirror_request_body` | boolean | true | Request Body an Shadow Backend senden |
| `mirror_headers` | boolean | true | Request Headers an Shadow Backend senden |
| `targets` | list | [] | Liste der Shadow Backend Targets |

### MirrorTarget

| Parameter | Typ | Default | Beschreibung |
|-----------|-----|---------|--------------|
| `name` | string | *required* | Eindeutiger Name fÃ¼r Shadow Target |
| `upstream` | object | *required* | Backend-Konfiguration (host, port) |
| `sample_percentage` | float | 100.0 | Prozent der Requests (0-100) |
| `timeout` | string | "5s" | Timeout fÃ¼r Shadow Requests |
| `headers` | dict | {} | Custom Headers fÃ¼r Shadow Backend |

---

## Provider-Implementierung

### 1. Envoy (âœ… Native)

**Mechanismus:** `request_mirror_policies`

```yaml
# Envoy Config (generiert von GAL)
clusters:
  - name: shadow_cluster
    connect_timeout: 5s
    type: STRICT_DNS
    dns_lookup_family: V4_ONLY
    load_assignment:
      cluster_name: shadow_cluster
      endpoints:
        - lb_endpoints:
          - endpoint:
              address:
                socket_address:
                  address: shadow-api-v2.internal
                  port_value: 8080

routes:
  - match:
      prefix: "/api/users"
    route:
      cluster: primary_cluster
      request_mirror_policies:
        - cluster: shadow_cluster
          runtime_fraction:
            default_value:
              numerator: 50    # 50% sampling
              denominator: HUNDRED
```

**Features:**
- âœ… Native `request_mirror_policies` support
- âœ… Sample percentage via `runtime_fraction`
- âœ… Custom headers via filter chains
- âœ… Multiple mirrors supported

**Envoy Version:** Envoy 1.10+

---

### 2. Nginx (âœ… Native)

**Mechanismus:** `mirror` directive

```nginx
# Nginx Config (generiert von GAL)
upstream shadow_backend {
    server shadow-api-v2.internal:8080;
}

server {
    listen 8080;

    location /api/users {
        # Primary backend
        proxy_pass http://api-v1.internal:8080;

        # Mirror to shadow backend
        mirror /mirror_shadow;
        mirror_request_body on;

        # 50% sampling via split_clients
        split_clients "${remote_addr}${request_uri}" $mirror_flag {
            50%     "1";
            *       "0";
        }
    }

    location = /mirror_shadow {
        internal;
        proxy_pass http://shadow_backend$request_uri;
        proxy_set_header X-Mirror "true";
        proxy_set_header X-Shadow-Version "v2";

        # Don't wait for shadow response
        proxy_ignore_client_abort on;
    }
}
```

**Features:**
- âœ… Native `mirror` directive (Nginx 1.13+)
- âœ… Sample percentage via `split_clients`
- âœ… Custom headers via `proxy_set_header`
- âœ… Multiple mirrors via multiple `mirror` directives

**Nginx Version:** Nginx 1.13.4+ (mirror directive support)

---

### 3. Apache APISIX (âœ… Native)

**Mechanismus:** `proxy-mirror` plugin

```yaml
# APISIX Config (generiert von GAL)
routes:
  - uri: /api/users
    methods: [GET, POST]
    upstream:
      nodes:
        "api-v1.internal:8080": 1
      type: roundrobin

    plugins:
      proxy-mirror:
        host: "http://shadow-api-v2.internal:8080"
        path: /api/users
        sample_ratio: 0.5  # 50% sampling
        request_headers:
          X-Mirror: "true"
          X-Shadow-Version: "v2"
```

**Features:**
- âœ… Native `proxy-mirror` plugin
- âœ… Sample percentage via `sample_ratio` (0.0-1.0)
- âœ… Custom headers via `request_headers`
- âœ… Multiple mirrors via multiple plugin instances

**APISIX Version:** APISIX 2.5+

---

### 4. HAProxy (âš ï¸ SPOE-basiert - HAProxy 2.0+)

**âš ï¸ WICHTIG: HAProxy unterstÃ¼tzt Request Mirroring Ã¼ber SPOE (Stream Processing Offload Engine)**

HAProxy hat **keine** einfache `http-request mirror` Direktive wie Nginx, sondern nutzt das **SPOE-Protokoll** (seit HAProxy 2.0) fÃ¼r Traffic Mirroring. Dies ist eine **native Funktion**, erfordert aber einen **externen SPOE Agent** (z.B. `spoa-mirror`).

**Mechanismus:** SPOE (Stream Processing Offload Engine) + spoa-mirror Agent

**Empfohlene LÃ¶sungen (sortiert nach KomplexitÃ¤t):**

#### Option 1: SPOE + spoa-mirror - **Native HAProxy LÃ¶sung** (HAProxy 2.0+) âœ…

**SPOE (Stream Processing Offload Engine)** ist die **native HAProxy-Methode** fÃ¼r Request Mirroring seit Version 2.0.

**Schritt 1: SPOE Agent (spoa-mirror) starten**

```bash
# spoa-mirror Agent kompilieren (aus HAProxy contrib/)
cd contrib/spoa_example
make

# spoa-mirror starten (lauscht auf Port 12345)
./spoa-mirror -p 12345 -f /etc/haproxy/spoa-mirror.conf
```

**Schritt 2: HAProxy Konfiguration**

```haproxy
# haproxy.cfg
global
    # SPOE Config einbinden
    log stdout format raw local0 info

backend spoe-mirror
    mode tcp
    # SPOE Agent Verbindung
    server spoe1 127.0.0.1:12345 check

frontend http_front
    bind *:8080
    mode http

    # SPOE Filter aktivieren fÃ¼r Request Mirroring
    filter spoe engine mirror config /etc/haproxy/spoe-mirror.conf

    # ACL fÃ¼r Sampling (50% der Requests)
    acl mirror_sample rand(50)
    http-request set-var(txn.mirror_enabled) bool(true) if mirror_sample

    default_backend primary_backend

backend primary_backend
    mode http
    server api1 api-v1.internal:8080 check
```

**Schritt 3: SPOE Konfiguration**

```
# /etc/haproxy/spoe-mirror.conf
[mirror]
spoe-agent mirror-agent
    messages   mirror-request
    option     async
    option     send-frag-payload
    timeout    hello      2s
    timeout    idle       2m
    timeout    processing 500ms
    use-backend spoe-mirror
    log        global

spoe-message mirror-request
    # Request Details an SPOE Agent senden
    args method=method path=path headers=req.hdrs body=req.body
    event on-frontend-http-request if { var(txn.mirror_enabled) -m bool }
```

**Schritt 4: spoa-mirror Agent Konfiguration**

```ini
# spoa-mirror.conf (fÃ¼r spoa-mirror binary)
[mirror]
# Shadow Backend URL
mirror-url = http://shadow-api-v2.internal:8080

# Custom Headers fÃ¼r gespiegelte Requests
mirror-headers = X-Mirror: true, X-Shadow-Version: v2

# Logging
log-level = info
```

**Vorteile:**
- âœ… **Native HAProxy-LÃ¶sung** (seit Version 2.0)
- âœ… Fire-and-forget (asynchron, wartet nicht auf Response)
- âœ… Sample percentage via `rand()` ACL
- âœ… Custom headers via SPOE Agent Config
- âœ… Production-ready in HAProxy Enterprise
- âœ… Multiple mirrors mÃ¶glich (mehrere SPOE Agents)

**Nachteile:**
- âš ï¸ Komplex: Erfordert externen SPOE Agent (`spoa-mirror`)
- âš ï¸ Setup: Agent muss kompiliert und deployed werden
- âš ï¸ Monitoring: ZusÃ¤tzlicher Prozess zu Ã¼berwachen

**HAProxy Version:** HAProxy 2.0+ (SPOE support)

---

#### Option 2: GoReplay (gor) - **Einfachste Alternative** â­

```bash
# GoReplay neben HAProxy deployen (keine HAProxy-Ã„nderung nÃ¶tig!)
docker run -d --name gor \
  --network host \
  goreplay/goreplay:latest \
  --input-raw :8080 \
  --output-http "http://shadow-api-v2.internal:8080" \
  --output-http-track-response

# Mit Sampling (50%)
gor --input-raw :8080 \
    --output-http "http://shadow-api-v2.internal:8080|50%"
```

**Vorteile:**
- âœ… **Einfachste LÃ¶sung** - keine HAProxy-Ã„nderung nÃ¶tig
- âœ… Production-ready, weit verbreitet
- âœ… Sample percentage support
- âœ… Request/Response tracking
- âœ… Filter by path, header, etc.

**Nachteile:**
- âš ï¸ Externe Dependency (nicht HAProxy-native)

---

#### Option 3: Teeproxy

```bash
# Teeproxy als Proxy vor HAProxy
teeproxy \
  -l :8080 \
  -a localhost:8081 \
  -b http://shadow-api-v2.internal:8080
```

**Nachteile:** Synchron, wartet auf beide Responses

---

#### Option 4: Lua Scripting

```haproxy
# haproxy.cfg (requires HAProxy with Lua support)
global
    lua-load /etc/haproxy/mirror.lua

frontend http_front
    http-request lua.mirror-request
```

```lua
-- mirror.lua
core.register_action("mirror-request", { "http-req" }, function(txn)
    -- Async HTTP request to shadow backend
    -- Implementation depends on Lua HTTP client
    -- NOT fire-and-forget by default!
end)
```

**Nachteile:** Lua nicht fire-and-forget, blockiert Request

---

**HAProxy Request Mirroring Features Zusammenfassung:**

| Feature | SPOE (Native) | GoReplay | Teeproxy | Lua |
|---------|---------------|----------|----------|-----|
| **Native HAProxy** | âœ… Ja (2.0+) | âŒ Nein | âŒ Nein | âš ï¸ Ja, aber komplex |
| **Fire-and-Forget** | âœ… Ja | âœ… Ja | âŒ Nein | âŒ Nein |
| **Sample Percentage** | âœ… Ja (`rand()`) | âœ… Ja | âŒ Nein | âœ… Ja |
| **Custom Headers** | âœ… Ja | âœ… Ja | âœ… Ja | âœ… Ja |
| **Multiple Mirrors** | âœ… Ja | âœ… Ja | âš ï¸ Limited | âœ… Ja |
| **Setup KomplexitÃ¤t** | ğŸ”´ Hoch | ğŸŸ¢ Niedrig | ğŸŸ¢ Niedrig | ğŸŸ¡ Mittel |
| **External Process** | âœ… SPOE Agent | âœ… gor | âœ… teeproxy | âŒ Nein |

**Empfehlung:**
- **Production HAProxy Setup:** SPOE + spoa-mirror (native, aber komplex)
- **Schnelles Testing/Staging:** GoReplay (einfach, keine HAProxy-Ã„nderung)
- **Development:** Teeproxy (einfach, aber synchron)

**HAProxy Routing-Konfiguration (von GAL generiert):**

```haproxy
# HAProxy Config fÃ¼r Routing (kein Mirroring)
frontend http_front
    bind *:8080
    mode http

    acl is_api_users path_beg /api/users
    use_backend api_backend if is_api_users

    default_backend api_backend

backend api_backend
    mode http
    server api1 api-v1.internal:8080 check
```

**GAL generiert HAProxy-Konfigurationen mit Routing, aber dokumentiert, dass externes Mirroring-Tool benÃ¶tigt wird.**

**Siehe auch:**
- [HAProxy Mirroring E2E Tests](../../tests/docker/haproxy-mirroring/README.md) - Dokumentiert Limitation
- [GoReplay GitHub](https://github.com/buger/goreplay) - Empfohlenes Tool
- [Teeproxy GitHub](https://github.com/chrissnell/teeproxy) - Alternative LÃ¶sung

---

### 5. Kong (âš ï¸ Partial - Plugin/Workaround)

**Mechanismus:** `request-transformer` + `post-function` oder Enterprise Plugin

**Kong Open Source Workaround:**

```yaml
# Kong Declarative Config (generiert von GAL)
services:
  - name: api_service
    url: http://api-v1.internal:8080

routes:
  - name: api_users_route
    paths:
      - /api/users
    service: api_service

plugins:
  # Option 1: post-function Plugin (Lua)
  - name: post-function
    route: api_users_route
    config:
      access:
        - |
          -- Mirror request to shadow backend
          local http = require "resty.http"
          local httpc = http.new()

          -- Sample 50% of requests
          if math.random() < 0.5 then
            httpc:request_uri("http://shadow-api-v2.internal:8080" .. kong.request.get_path(), {
              method = kong.request.get_method(),
              body = kong.request.get_raw_body(),
              headers = {
                ["X-Mirror"] = "true",
                ["X-Shadow-Version"] = "v2"
              }
            })
          end
```

**Kong Enterprise:**
```yaml
plugins:
  # Option 2: request-transformer-advanced (Enterprise)
  - name: request-transformer-advanced
    config:
      add:
        headers:
          - "X-Mirror: true"
      mirror:
        enabled: true
        upstream_url: "http://shadow-api-v2.internal:8080"
        sample_percentage: 50
```

**Features:**
- âš ï¸ Open Source: Lua Scripting erforderlich
- âœ… Enterprise: Native plugin support
- âœ… Sample percentage via Lua `math.random()` oder Enterprise config
- âœ… Custom headers supported

**Kong Version:** Kong 2.0+

---

### 6. Traefik (âš ï¸ Limited - Custom Middleware)

**Mechanismus:** Custom Middleware (Plugin erforderlich)

**Traefik Middleware (Custom Plugin erforderlich):**

```yaml
# Traefik Config (generiert von GAL)
http:
  routers:
    api-router:
      rule: "PathPrefix(`/api/users`)"
      service: api-service
      middlewares:
        - mirror-middleware

  services:
    api-service:
      loadBalancer:
        servers:
          - url: "http://api-v1.internal:8080"

  middlewares:
    mirror-middleware:
      plugin:
        traefik-mirror-plugin:
          shadow_url: "http://shadow-api-v2.internal:8080"
          sample_percentage: 50
          headers:
            X-Mirror: "true"
            X-Shadow-Version: "v2"
```

**âš ï¸ Achtung:** Traefik hat KEIN natives Request Mirroring Feature. Ein Custom Plugin muss entwickelt werden.

**Workaround:**
- Entwickle ein Traefik Plugin (Go)
- Oder verwende einen externen Service Mesh (Linkerd, Istio)

**Features:**
- âš ï¸ Custom Plugin erforderlich
- âš ï¸ Kein natives Feature in Traefik

---

### 7. Azure API Management (âœ… Native)

**Mechanismus:** `send-request` policy

```xml
<!-- Azure APIM Policy (generiert von GAL) -->
<policies>
    <inbound>
        <base />

        <!-- Mirror Request to Shadow Backend -->
        <choose>
            <when condition="@(new Random().Next(100) < 50)">
                <send-request mode="new" response-variable-name="mirrorResponse"
                              timeout="5" ignore-error="true">
                    <set-url>http://shadow-api-v2.internal:8080@(context.Request.Url.Path)</set-url>
                    <set-method>@(context.Request.Method)</set-method>
                    <set-header name="X-Mirror" exists-action="override">
                        <value>true</value>
                    </set-header>
                    <set-header name="X-Shadow-Version" exists-action="override">
                        <value>v2</value>
                    </set-header>
                    <set-body>@(context.Request.Body.As<string>(preserveContent: true))</set-body>
                </send-request>
            </when>
        </choose>
    </inbound>

    <backend>
        <!-- Primary backend -->
        <base />
    </backend>
</policies>
```

**Features:**
- âœ… Native `send-request` policy
- âœ… Sample percentage via `<choose>` + Random
- âœ… Custom headers via `<set-header>`
- âœ… Multiple mirrors via multiple `send-request`
- âœ… `ignore-error="true"` â†’ Shadow Response wird ignoriert

**Azure APIM Tier:** Standard oder Premium

---

### 8. AWS API Gateway (âš ï¸ Workaround - Lambda@Edge)

**Mechanismus:** Lambda@Edge Function

**GAL Config:**

```yaml
global_config:
  aws_apigateway:
    api_name: "MyAPI"
    # Request Mirroring Workaround
    mirroring_workaround: "lambda_edge"
    mirroring_lambda_edge_arn: "arn:aws:lambda:us-east-1:123456789012:function:mirror-traffic"
```

**Lambda@Edge Function (Nutzer muss erstellen):**

```javascript
// Lambda@Edge Function fÃ¼r Request Mirroring
const https = require('https');

exports.handler = async (event) => {
    const request = event.Records[0].cf.request;

    // Sample 50% of requests
    if (Math.random() < 0.5) {
        // Mirror request to shadow backend
        const options = {
            hostname: 'shadow-api-v2.internal',
            port: 8080,
            path: request.uri,
            method: request.method,
            headers: {
                ...request.headers,
                'x-mirror': 'true',
                'x-shadow-version': 'v2'
            }
        };

        // Send mirrored request (fire-and-forget)
        const req = https.request(options);
        if (request.body && request.body.data) {
            req.write(Buffer.from(request.body.data, request.body.encoding));
        }
        req.end();
    }

    // Return original request (no modifications)
    return request;
};
```

**Features:**
- âš ï¸ Lambda@Edge erforderlich (Custom Code)
- âœ… Sample percentage via JavaScript `Math.random()`
- âœ… Custom headers supported
- âš ï¸ ZusÃ¤tzliche Kosten fÃ¼r Lambda Invocations

**AWS Regions:** Lambda@Edge muss in `us-east-1` deployed werden

---

### 9. GCP API Gateway (âš ï¸ Workaround - Cloud Functions)

**Mechanismus:** Cloud Functions

**GAL Config:**

```yaml
global_config:
  gcp_apigateway:
    api_id: "my-api"
    project_id: "my-project"
    # Request Mirroring Workaround
    mirroring_workaround: "cloud_functions"
    mirroring_cloud_function_url: "https://us-central1-my-project.cloudfunctions.net/mirror-traffic"
```

**Cloud Function (Nutzer muss erstellen):**

```javascript
// Cloud Function fÃ¼r Request Mirroring
const axios = require('axios');

exports.mirrorTraffic = async (req, res) => {
    // Sample 50% of requests
    if (Math.random() < 0.5) {
        // Mirror request to shadow backend
        try {
            await axios({
                method: req.method,
                url: `http://shadow-api-v2.internal:8080${req.path}`,
                headers: {
                    ...req.headers,
                    'x-mirror': 'true',
                    'x-shadow-version': 'v2'
                },
                data: req.body,
                timeout: 5000
            });
        } catch (error) {
            // Ignore errors from shadow backend
            console.error('Mirror request failed:', error.message);
        }
    }

    // Always return success (don't block primary request)
    res.status(200).send('OK');
};
```

**Features:**
- âš ï¸ Cloud Functions erforderlich (Custom Code)
- âœ… Sample percentage via JavaScript `Math.random()`
- âœ… Custom headers supported
- âš ï¸ ZusÃ¤tzliche Kosten fÃ¼r Cloud Functions Invocations

---

## HÃ¤ufige AnwendungsfÃ¤lle

### 1. Canary Deployment (5% â†’ 100%)

**Schrittweise neue Version mit Shadow Traffic testen:**

```yaml
# Phase 1: 5% Shadow Traffic
mirroring:
  enabled: true
  targets:
    - name: canary-v2
      upstream:
        host: api-v2.internal
        port: 8080
      sample_percentage: 5.0  # Start mit 5%
```

**Rollout-Plan:**
1. **Woche 1:** 5% Shadow Traffic â†’ Metriken Ã¼berwachen
2. **Woche 2:** 25% Shadow Traffic â†’ Bug-Reports prÃ¼fen
3. **Woche 3:** 50% Shadow Traffic â†’ Performance validieren
4. **Woche 4:** 100% Shadow Traffic â†’ Full Production Test
5. **Woche 5:** Traffic Splitting aktivieren (Feature 5) â†’ Echte User-Requests

---

### 2. Performance Testing unter realer Last

**Shadow Backend Performance messen:**

```yaml
mirroring:
  enabled: true
  targets:
    - name: performance-test
      upstream:
        host: new-api-optimized.internal
        port: 8080
      sample_percentage: 100.0  # Alle Requests
      headers:
        X-Test-Run: "performance-test-2024-01"
```

**Metriken sammeln:**
```bash
# Shadow Backend Prometheus Metrics
curl http://new-api-optimized.internal:8080/metrics | grep http_request_duration

# CloudWatch Logs (AWS)
aws logs tail /aws/apigateway/shadow-backend --follow
```

---

### 3. Bug Detection vor Production Rollout

**Neue Version mit Shadow Traffic testen:**

```yaml
mirroring:
  enabled: true
  targets:
    - name: bug-detection-v2
      upstream:
        host: api-v2-staging.internal
        port: 8080
      sample_percentage: 50.0
      headers:
        X-Environment: "shadow"
        X-Bug-Tracking: "enabled"
```

**Error Tracking aktivieren:**
```python
# Shadow Backend Error Handler
@app.errorhandler(Exception)
def handle_shadow_error(error):
    if request.headers.get('X-Environment') == 'shadow':
        # Log error to Sentry/DataDog
        sentry.capture_exception(error)
        # Don't crash - shadow errors are ignored
        return jsonify({"error": "shadow"}), 500
    else:
        # Production errors should crash
        raise error
```

---

### 4. Multi-Version Testing (A/B/C Testing)

**3 Versionen gleichzeitig testen:**

```yaml
mirroring:
  enabled: true
  targets:
    - name: shadow-v2
      upstream:
        host: api-v2.internal
        port: 8080
      sample_percentage: 33.0  # 33% v2
      headers:
        X-Version: "v2"

    - name: shadow-v3
      upstream:
        host: api-v3.internal
        port: 8080
      sample_percentage: 33.0  # 33% v3
      headers:
        X-Version: "v3"
```

**Result:**
- 33% Requests â†’ v2 Shadow Backend
- 33% Requests â†’ v3 Shadow Backend
- 34% Requests â†’ Kein Shadow (nur Primary)

---

### 5. Data Collection fÃ¼r Machine Learning

**Requests fÃ¼r ML Training sammeln:**

```yaml
mirroring:
  enabled: true
  targets:
    - name: ml-data-collector
      upstream:
        host: ml-collector.internal
        port: 8080
      sample_percentage: 10.0  # 10% sampling
      headers:
        X-Data-Collection: "ml-training"
        X-Dataset: "production-2024"
```

**ML Collector Backend:**
```python
@app.post("/api/users")
def collect_data():
    # Store request/response for ML training
    request_data = {
        "timestamp": datetime.utcnow(),
        "request": request.json,
        "headers": dict(request.headers)
    }

    # Save to S3/BigQuery
    save_to_dataset(request_data)

    return {"status": "collected"}, 200
```

---

## Best Practices

### 1. Sample Percentage sinnvoll wÃ¤hlen

**Empfohlene Werte:**

| Use Case | Sample % | BegrÃ¼ndung |
|----------|----------|------------|
| **Canary Start** | 1-5% | Minimales Risiko, erste Fehler finden |
| **Performance Testing** | 25-50% | ReprÃ¤sentative Last, nicht zu teuer |
| **Full Production Test** | 100% | Finale Validation vor Rollout |
| **Data Collection** | 5-10% | Genug Daten, nicht zu viele Kosten |
| **Bug Detection** | 50-100% | Maximale Coverage fÃ¼r Fehler |

### 2. Shadow Backend Monitoring

**Wichtige Metriken Ã¼berwachen:**

```yaml
# Prometheus Metrics fÃ¼r Shadow Backend
http_request_duration_seconds{backend="shadow"}
http_request_errors_total{backend="shadow"}
http_request_count{backend="shadow"}
```

**Alerts einrichten:**
```yaml
# Prometheus Alert fÃ¼r Shadow Errors
- alert: ShadowBackendHighErrorRate
  expr: |
    rate(http_request_errors_total{backend="shadow"}[5m]) > 0.05
  for: 10m
  annotations:
    summary: "Shadow Backend hat erhÃ¶hte Error Rate (>5%)"
```

### 3. Timeout konfigurieren

**Shadow Requests sollten kurze Timeouts haben:**

```yaml
mirroring:
  targets:
    - name: shadow
      timeout: "3s"  # Kurzer Timeout (Standard: 5s)
```

**Warum?**
- Shadow Requests sollten Primary Request nicht verzÃ¶gern
- Langsame Shadow Backends sollten Primary nicht blockieren

### 4. Headers fÃ¼r Shadow identifizieren

**Immer X-Mirror Header setzen:**

```yaml
mirroring:
  targets:
    - name: shadow
      headers:
        X-Mirror: "true"              # Shadow Backend kann ignorieren
        X-Shadow-Version: "v2"        # Versionierung
        X-Request-ID: "{{uuid}}"      # Tracing
        X-Environment: "shadow"       # Environment Tag
```

**Shadow Backend kann dann:**
- Errors ignorieren (nicht zu Sentry senden)
- Separate Logging aktivieren
- Separate Metriken sammeln

### 5. Shadow Response ignorieren

**Wichtig:** Shadow Response sollte NIEMALS die Primary Response beeinflussen!

```python
# Shadow Backend Error Handling
@app.errorhandler(500)
def handle_error(error):
    if request.headers.get('X-Mirror') == 'true':
        # Shadow Request - Error ignorieren
        logger.warning(f"Shadow request error: {error}")
        return {"status": "shadow_error"}, 500
    else:
        # Primary Request - Error propagieren
        raise error
```

### 6. Costs Ã¼berwachen (Cloud Provider)

**Cloud Provider berechnen Shadow Requests:**

| Provider | Kosten | Hinweise |
|----------|--------|----------|
| **AWS Lambda@Edge** | $0.60 / 1M requests | ZusÃ¤tzlich zu API Gateway |
| **GCP Cloud Functions** | $0.40 / 1M invocations | ZusÃ¤tzlich zu API Gateway |
| **Azure APIM** | Inkludiert | Keine zusÃ¤tzlichen Kosten fÃ¼r `send-request` |

**Empfehlung:** Sample Percentage reduzieren (z.B. 10% statt 100%), um Kosten zu sparen.

---

## Request Mirroring Testen

### 1. Lokales Testing mit Docker Compose

**docker-compose.yml:**

```yaml
version: '3.8'

services:
  gateway:
    image: envoyproxy/envoy:v1.27-latest
    volumes:
      - ./envoy.yaml:/etc/envoy/envoy.yaml
    ports:
      - "8080:8080"

  primary-backend:
    image: kennethreitz/httpbin
    environment:
      - SERVICE_NAME=primary
    ports:
      - "8081:80"

  shadow-backend:
    image: kennethreitz/httpbin
    environment:
      - SERVICE_NAME=shadow
    ports:
      - "8082:80"
```

**Test ausfÃ¼hren:**

```bash
# Gateway starten
docker-compose up -d

# Request senden
curl http://localhost:8080/api/users

# Primary Backend Logs
docker-compose logs primary-backend

# Shadow Backend Logs
docker-compose logs shadow-backend
```

### 2. Sample Percentage validieren

**Test-Script:**

```bash
#!/bin/bash
# test-mirroring-percentage.sh

TOTAL_REQUESTS=1000
GATEWAY_URL="http://localhost:8080/api/users"
SHADOW_URL="http://localhost:8082/metrics"

# Send requests
for i in $(seq 1 $TOTAL_REQUESTS); do
    curl -s $GATEWAY_URL > /dev/null
done

# Check shadow backend request count
SHADOW_REQUESTS=$(curl -s $SHADOW_URL | grep 'http_requests_total' | awk '{print $2}')

echo "Total Requests: $TOTAL_REQUESTS"
echo "Shadow Requests: $SHADOW_REQUESTS"
echo "Sample Percentage: $(echo "scale=2; $SHADOW_REQUESTS / $TOTAL_REQUESTS * 100" | bc)%"
```

**Expected Output (50% sampling):**
```
Total Requests: 1000
Shadow Requests: 503
Sample Percentage: 50.30%
```

### 3. Custom Headers validieren

**Test-Script:**

```bash
# Request mit Header-Inspektion
curl -v http://localhost:8080/api/users 2>&1 | grep -i 'x-mirror'

# Shadow Backend Request prÃ¼fen
docker-compose exec shadow-backend cat /var/log/requests.log | grep 'X-Mirror'
```

**Expected Output:**
```
X-Mirror: true
X-Shadow-Version: v2
```

---

## Troubleshooting

### Problem 1: Shadow Requests kommen nicht an

**Symptome:**
- Primary Backend funktioniert
- Shadow Backend erhÃ¤lt keine Requests

**LÃ¶sungen:**

1. **Provider Logs prÃ¼fen:**
```bash
# Envoy
docker logs gateway-container 2>&1 | grep mirror

# Nginx
nginx -T | grep mirror

# HAProxy
haproxy -c -f /etc/haproxy/haproxy.cfg
```

2. **Network Connectivity testen:**
```bash
# Von Gateway zu Shadow Backend
docker exec gateway-container curl http://shadow-backend:8080/health
```

3. **Sample Percentage erhÃ¶hen:**
```yaml
# TemporÃ¤r auf 100% setzen
mirroring:
  targets:
    - sample_percentage: 100.0
```

---

### Problem 2: Shadow Backend verlangsamt Primary Requests

**Symptome:**
- Primary Response Latency erhÃ¶ht
- Gateway Logs zeigen Timeouts

**LÃ¶sungen:**

1. **Timeout reduzieren:**
```yaml
mirroring:
  targets:
    - timeout: "1s"  # Sehr kurzer Timeout
```

2. **Fire-and-forget sicherstellen:**
```bash
# Envoy: async_client verwendet?
envoy.yaml: request_mirror_policies (automatisch async)

# Nginx: mirror_request_body on?
nginx.conf: proxy_ignore_client_abort on;
```

3. **Sample Percentage reduzieren:**
```yaml
mirroring:
  targets:
    - sample_percentage: 25.0  # Weniger Last
```

---

### Problem 3: Cloud Provider Workaround funktioniert nicht

**AWS Lambda@Edge:**

```bash
# Lambda Function Logs prÃ¼fen
aws logs tail /aws/lambda/us-east-1.mirror-traffic --follow

# Lambda Execution Role prÃ¼fen
aws iam get-role --role-name lambda-edge-execution-role

# CloudFront Distribution prÃ¼fen
aws cloudfront get-distribution --id E1234567890ABC
```

**GCP Cloud Functions:**

```bash
# Function Logs prÃ¼fen
gcloud functions logs read mirror-traffic --limit=50

# Function Status prÃ¼fen
gcloud functions describe mirror-traffic --region=us-central1

# Network Connectivity testen
gcloud functions call mirror-traffic --data='{"test":"true"}'
```

---

### Problem 4: Sample Percentage zu hoch/niedrig

**Symptome:**
- Erwartete 50%, aber nur 30% Shadow Requests
- Oder: 50% konfiguriert, aber 100% Shadow Requests

**LÃ¶sungen:**

1. **Sample Percentage Validation:**
```python
# Test-Script
import requests
import time

TOTAL = 1000
shadow_count = 0

for _ in range(TOTAL):
    response = requests.get("http://localhost:8080/api/users")
    # Check if shadow backend was called (via custom header or logs)
    shadow_count += check_shadow_backend_called()
    time.sleep(0.01)

print(f"Actual Sample %: {shadow_count / TOTAL * 100:.2f}%")
```

2. **Provider-spezifische Debugging:**

**Envoy:** `runtime_fraction` prÃ¼fen
```yaml
runtime_fraction:
  default_value:
    numerator: 50      # Check this value
    denominator: HUNDRED
```

**Nginx:** `split_clients` prÃ¼fen
```nginx
split_clients "${remote_addr}${request_uri}" $mirror_flag {
    50%     "1";    # Check this percentage
    *       "0";
}
```

---

## Verwandte Themen

- [Traffic Splitting Guide](TRAFFIC_SPLITTING.md) - A/B Testing, Canary Deployments
- [Provider Ãœbersicht](PROVIDERS.md) - Provider-spezifische Features
- [Best Practices](BEST_PRACTICES.md) - Allgemeine Best Practices

---

**Status:** âœ… Request Mirroring ist implementiert fÃ¼r 9/9 Provider (Feature 6 abgeschlossen)
**Version:** GAL v1.4.0+
**Letzte Aktualisierung:** 2025-10-22
